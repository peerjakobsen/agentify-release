# Product Roadmap

## Phase 1: Foundation (MVP)

1. [x] DynamoDB Observability Table â€” Create `agentify-workflow-events` DynamoDB table with workflow_id partition key, timestamp sort key, event_type, agent_name, payload, and TTL configuration `S`

2. [x] Agentify Extension Shell â€” Create single Kiro IDE extension with shared services (AWS clients, config, types) and registration for two webview panels: Demo Viewer (runtime) and Ideation Wizard (design-time) `S`

3. [x] AWS Credential Chain Integration â€” Use AWS SDK's default credential provider chain to automatically consume credentials from shared AWS config files (~/.aws/credentials, ~/.aws/config), supporting IAM credentials, IAM Identity Center (SSO), and assumed roles configured via AWS CLI or AWS Toolkit; add project-level region configuration in .agentify/config.json for DynamoDB and Bedrock API calls `S`

4. [x] Project Initialization Command â€” Add "Agentify: Initialize Project" command that: (1) checks AWS credentials via default credential chain, (2) validates DynamoDB table exists using tableValidator service, (3) if table missing, prompts user to deploy using bundled `infrastructure/dynamodb-table.yaml` template via CloudFormation SDK, (4) waits for stack CREATE_COMPLETE, (5) generates `.agentify/config.json` with table name, region, and stack name, (6) creates `.kiro/steering/agentify-integration.md` steering file. The CloudFormation template from spec #1 is packaged with the extension for automated deployment. `M`

5. [x] Workflow Input Panel â€” Build Demo Viewer input panel with: (1) multi-line prompt textarea (button submit only, no Enter shortcut), (2) Run Workflow button that spawns `agents/main.py` with `--prompt`, `--workflow-id`, and `--trace-id` CLI args, (3) hybrid identity display showing short `workflow_id` (wf-xxx) with copy button and OTEL `trace_id` with optional X-Ray console link, (4) execution timer, (5) validation states for missing entry script or AWS credentials. The `main.py` is generated by Kiro spec-driven development, not by this extension. `M`

6. [x] Execution Log Panel â€” Create chronological log panel displaying events from DynamoDB with timestamps, event types, agent names, and expandable payload details `M`

7. [x] Outcome Panel â€” Build outcome display section in Demo Viewer (below Execution Log) showing: (1) success/failure status with âœ…/âŒ icon from `workflow_complete` or `workflow_error` stdout events, (2) workflow result rendered as markdown when result is a string, with formatted JSON fallback (syntax highlighting, collapsible) for structured objects, (3) "Sources" line listing data sources used if provided in outcome payload, (4) copy-to-clipboard button for result content. Panel starts hidden/collapsed until first workflow completes, clears immediately when new run starts (not waiting for new outcome). Error state displays error message prominently without stack trace â€” keep it clean for demo audiences. Does NOT duplicate execution duration (already shown in Input Panel timer). `S`

8. [x] DynamoDB Polling Service â€” Implement polling service for workflow events: (1) poll `infrastructure.dynamodb.tableName` every 500ms using AWS SDK DocumentClient, (2) query by `workflow_id` (partition key) with `timestamp` (sort key) greater than last-polled timestamp to fetch only new events, (3) start polling when `handleRunWorkflow()` generates a workflow_id, (4) stop polling on `workflow_complete`/`workflow_error` event, panel dispose, or new workflow run, (5) exponential backoff on errors (1s, 2s, 4s, max 30s) with automatic recovery, (6) emit events to subscribers (for merging with stdout stream), (7) track seen event IDs for deduplication. Service is separate from panel lifecycle â€” panel subscribes to events, service manages AWS calls. `M`

9. [x] Observability Steering Documentation â€” Expand `.kiro/steering/agentify-integration.md` (created in item 4) with complete implementation guidance for Kiro-generated agent code:

**CLI Contract:**
- `agents/main.py` must accept `--prompt`, `--workflow-id`, `--trace-id` via argparse
- Read `AGENTIFY_TABLE_NAME` and `AGENTIFY_TABLE_REGION` environment variables
- Example argparse setup code snippet

**Hybrid Identity Pattern:**
- `workflow_id`: Short ID (wf-{8-char}) for UI display and DynamoDB partition key
- `trace_id`: 32-char hex OTEL trace ID for X-Ray correlation
- Both IDs included in every emitted event

**stdout Event Streaming (real-time, for graph visualization):**
- JSON Lines format (one JSON object per line to stdout)
- Event types: `graph_structure` (topology at start), `node_start`/`node_stream`/`node_stop` (agent lifecycle), `workflow_complete`/`workflow_error` (terminal)
- Schema: `{"workflow_id": "...", "trace_id": "...", "timestamp": 1234567890, "event_type": "...", "payload": {...}}`
- Example: mapping Strands `stream_async()` callbacks to stdout events

**DynamoDB Event Persistence (for tool calls and history):**
- Event types: `tool_call`, `tool_result`, `agent_start`, `agent_end`, `handoff`
- Write to table from `AGENTIFY_TABLE_NAME` env var using boto3
- Include TTL field for automatic cleanup
- Example: `emit_event()` helper function pattern

**Strands SDK Integration:**
- `StrandsTelemetry` setup for OTEL trace propagation
- `stream_async()` event callback mapping to stdout JSON lines
- Agent decorator patterns for consistent event emission

This steering file is the source of truth for Kiro's code generation â€” all generated agents must follow these patterns. `M`

10. [x] Workflow Trigger Service â€” Extract subprocess execution logic from `DemoViewerPanel.handleRunWorkflow()` into a dedicated service with clean separation:

**ID Generation:**
- `workflow_id`: `wf-{8-char-uuid}` (e.g., `wf-a1b2c3d4`)
- `trace_id`: 32-char hex string, OTEL-compatible (e.g., `80e1afed08e019fc1110464cfa66635c`)

**Subprocess Spawning:**
- Command: `{workflow.pythonPath} {workflow.entryScript}` from `.agentify/config.json`
- CLI args: `--prompt`, `--workflow-id`, `--trace-id`
- Env vars: `AGENTIFY_TABLE_NAME` (from `infrastructure.dynamodb.tableName`), `AGENTIFY_TABLE_REGION` (from `infrastructure.dynamodb.region`)
- Working directory: workspace root

**Event Emission (vscode.EventEmitter pattern):**
- `onStdoutLine: Event<string>` â€” raw stdout lines (item 11 parses these)
- `onStderr: Event<string>` â€” stderr output for error display
- `onProcessStateChange: Event<ProcessState>` â€” `idle` | `running` | `completed` | `failed` | `killed`
- `onProcessExit: Event<{code: number | null, signal: string | null}>`

**Process Lifecycle:**
- `start(prompt: string): {workflowId, traceId}` â€” spawns process, returns IDs
- `kill(): void` â€” terminates current process (for reset/new run)
- `getState(): ProcessState` â€” current process state
- Only one workflow at a time â€” calling `start()` while running kills previous process

**Integration:**
- Singleton service (like `DynamoDbPollingService`)
- `DemoViewerPanel.handleRunWorkflow()` calls this service instead of spawning directly
- Panel subscribes to events for UI updates

This service handles raw subprocess I/O; stdout JSON parsing is handled by item 11. `M`

11. [x] stdout Event Streaming & Panel Integration â€” Parse real-time JSON line events from `WorkflowTriggerService.onStdoutLine` following the schema in `agentify-integration.md`: `graph_structure`, `node_start`/`node_stream`/`node_stop`, `tool_call`/`tool_result`, `workflow_complete`/`workflow_error`. Create `StdoutEventParser` service that:

**Parsing:**
- Subscribes to `WorkflowTriggerService.onStdoutLine`
- Parses JSON, validates against event schema
- Emits typed `StdoutEvent` via `vscode.EventEmitter`
- Handles malformed JSON gracefully (log warning, skip)

**Panel Integration:**
- `DemoViewerPanel` subscribes to both `StdoutEventParser.onEvent` and `DynamoDbPollingService.onEvent`
- Events collected into single array, sorted by timestamp for Execution Log display
- `workflow_complete`/`workflow_error` events trigger Outcome Panel update
- `graph_structure`/`node_*` events reserved for Phase 4 Agent Graph visualization

No separate merge service needed â€” panel handles trivial array combination. `M`

## Phase 2: AI-Assisted Ideation

13. [x] Ideation Wizard Panel & Business Objective Step â€” Create Ideation Wizard webview panel with multi-step wizard navigation framework (step indicator, next/back buttons, progress tracking), then build the first step with: (1) multi-line text input for business objective/problem statement, (2) industry vertical dropdown (Retail, FSI, Healthcare, Life Sciences, Manufacturing, Energy, Telecom, Public Sector, Media & Entertainment, Travel & Hospitality, Other) with conditional "Other industry" free-text field when "Other" is selected, (3) system checkboxes grouped by category â€” CRM (Salesforce, HubSpot, Dynamics), ERP (SAP S/4HANA, Oracle, NetSuite), Data (Databricks, Snowflake, Redshift), HR (Workday, SuccessFactors), Service (ServiceNow, Zendesk), (4) "Other systems" free-text field, (5) optional file upload for additional context (account plan, requirements doc â€” stored in memory, not persisted). Wizard state held in memory; file persistence added in item 22. `M`

14. [x] Claude Bedrock Integration â€” Implement Amazon Bedrock client service for Claude API calls:

**Client Setup:**
- Use `@aws-sdk/client-bedrock-runtime` with credential chain from shared AWS services
- Model: `global.anthropic.claude-opus-4-5-20251101-v1:0` (configurable in `.agentify/config.json`)
- Region from `infrastructure.dynamodb.region` (same as DynamoDB)
- Use **Converse API** (`ConverseStreamCommand`) â€” the unified, model-agnostic interface

**Conversation Management:**
- `BedrockConversationService` singleton with `vscode.EventEmitter` pattern
- Maintain conversation history using Converse API message format:
```typescript
  interface Message {
    role: 'user' | 'assistant';
    content: Array<{ text: string }>;
  }
```
- System prompt loaded from bundled `prompts/ideation-assistant.md`, passed via `system` parameter
- `sendMessage(userMessage: string): AsyncIterable<string>` â€” streaming response
- `resetConversation(): void` â€” clear history for new ideation session

**Streaming to Webview:**
- Use `ConverseStreamCommand` from Converse API
- Async iterate `response.stream`, extract `contentBlockDelta.delta.text` tokens
- Emit tokens via `onToken: Event<string>`
- Emit `onComplete: Event<string>` with full response on `messageStop` event
- Handle `ThrottlingException` with exponential backoff (1s, 2s, 4s, max 30s)

**Error Handling:**
- `onError: Event<BedrockError>` for UI display
- Graceful handling of model access errors (user may not have Bedrock enabled)
- Handle `AccessDeniedException` for cross-region inference SCP issues `M`

15. [x] AI Gap-Filling Conversation â€” Create wizard step 2 as a conversational UI where the model analyzes the business objective and system selections, then proposes industry-typical assumptions:

**Conversation Flow:**
1. On step entry, auto-send context summary to Bedrock: "User's objective: {objective}. Industry: {industry}. Known systems: {systems}."
2. Model responds with structured proposal: "Based on your {industry} context, here's what I'm assuming about your environment..." with specific module/integration assumptions
3. User can accept all, or reply with corrections: "Actually we use SAP IBP, not APO"
4. Model acknowledges and refines: "Got it, updating to SAP IBP for demand planning..."
5. Conversation continues until user clicks "Confirm & Continue"

**UI Pattern:**
- Chat-style interface with AI messages (left-aligned) and user messages (right-aligned)
- AI messages include "Accept Assumptions" button for quick confirmation
- Editable text input for user refinements
- Streaming token display as model responds
- "Regenerate" button to get fresh proposal

**State Output:**
- `confirmedAssumptions: {system: string, modules: string[], integrations: string[]}[]`
- Stored in wizard state for downstream steps `L`

16. [x] Outcome Definition Step â€” Build wizard step 3 for defining measurable business outcomes:

**AI-Driven Suggestions on Step Entry:**
- Auto-send context (objective, industry, assumptions from Step 2) to Bedrock
- Model returns JSON with suggested primary outcome, KPIs, and relevant stakeholders
- Display suggestions as editable starting points, not locked values

**Fields:**
- Primary outcome statement (text input pre-filled with AI suggestion, fully editable)
- Success metrics (repeatable field group with AI-suggested KPIs, user can edit/add/remove)
- Stakeholders (multi-select with AI-suggested options pre-checked, user can uncheck/add custom)

**User Control:**
- All AI suggestions are editable, removable, or ignorable
- "Add Custom" option always available for each field
- "Regenerate Suggestions" button for fresh AI proposal
- User modifications take precedence over AI suggestions

**Fallback:**
- If AI fails: show static stakeholder list (Internal/External groups) and empty fields
- Manual entry always works regardless of AI status

**Validation:**
- Primary outcome required
- At least one success metric recommended (warning, not blocking) `S`

16.2. [x] Panel Architecture Consolidation â€” Consolidate duplicate ideation wizard implementations into single `tabbedPanel.ts`:

**Current State:**
- `src/panels/ideationWizardPanel.ts` (~3000 lines): Original standalone wizard with complete AI integration for Steps 1-3, including `OutcomeDefinitionService` integration, streaming handlers, and conversation management
- `src/panels/tabbedPanel.ts` (~2100 lines): Newer unified tabbed panel (Ideation + Demo Viewer) currently used by the app, with manual Step 3 implementation (no AI)

**Problem:**
- Two parallel implementations cause confusion during development
- AI integration code in `ideationWizardPanel.ts` is not being used
- Step 3 in `tabbedPanel.ts` lacks AI-driven suggestions that exist in `ideationWizardPanel.ts`

**Migration Tasks:**

1. **Port AI Integration for Step 3:**
   - Import and initialize `OutcomeDefinitionService` in `tabbedPanel.ts`
   - Add `_outcomeService` and `_outcomeStreamingResponse` private members
   - Implement `initOutcomeService()` method with event subscriptions
   - Implement `triggerAutoSendForStep3()` to auto-send context on step entry
   - Implement `sendOutcomeContextToClaude()` for AI suggestions
   - Add streaming handlers: `handleOutcomeStreamingToken()`, `handleOutcomeStreamingComplete()`, `handleOutcomeStreamingError()`

2. **Port Type Definitions:**
   - Verify `OutcomeSuggestions` interface from `wizardPanel.ts` is used
   - Ensure `parseOutcomeSuggestionsFromResponse()` from service is called

3. **Update Step Navigation:**
   - Add `triggerAutoSendForStep3()` call in `ideationNavigateForward()` when entering Step 3 from Step 2

4. **Port Prompt Template:**
   - Ensure `resources/prompts/outcome-definition-assistant.md` is loaded by service

5. **Delete Redundant Code:**
   - Remove `src/panels/ideationWizardPanel.ts` entirely
   - Remove `IDEATION_WIZARD_VIEW_ID` export and any package.json references
   - Clean up any unused imports in extension.ts

6. **Update Tests:**
   - Move relevant tests from `ideationWizardPanel.*.test.ts` to tabbedPanel tests
   - Delete `src/test/panels/ideationWizardPanel.*.test.ts` files

**Verification:**
- Step 3 auto-generates AI suggestions on entry (like Step 2 does)
- Regenerate button fetches fresh AI suggestions
- AI suggestions populate form fields (primary outcome, metrics, stakeholders)
- User edits are preserved and not overwritten by subsequent AI calls
- All existing Step 1-2 functionality unchanged `M`

16.5. [x] Outcome Refinement Conversation â€” Add conversational refinement UI to Step 3, matching the Step 2 pattern:

**Two-Phase Display:**
- **Phase 1 (Suggestion Review)**: On step entry, display AI suggestions as read-only card (not editable form)
  - Card shows: Primary Outcome statement, Suggested KPIs as bullet list, Suggested Stakeholders as tags
  - "Accept Suggestions" button (green, full-width) to transition to Phase 2
  - Refine input visible below card for pre-acceptance adjustments
- **Phase 2 (Editable Form)**: After acceptance, show current editable form (from item 16)
  - "Accepted âœ“" banner at top (matches Step 2 pattern)
  - All fields now editable (textarea, metric rows, stakeholder checkboxes)
  - Refine input remains visible for post-acceptance adjustments

**Refine Input (Both Phases):**
- Text input with placeholder: "Refine outcomes..."
- "Send" button to submit refinement request
- Example hints below input: "Add a metric for cost savings", "Make the outcome more specific to risk"
- Sends natural language request to Claude with current outcome state as context
- AI responds with updated suggestions (Phase 1) or directly updates form fields (Phase 2)

**Refinement Handling:**
- Parse AI response for structured changes: outcome text updates, KPI additions/removals/edits, stakeholder changes
- In Phase 1: Update suggestion card with refined values
- In Phase 2: Update form fields directly, preserve user's other manual edits
- Show brief "Updating..." indicator while AI processes refinement

**State Management:**
- New field: `suggestionsAccepted: boolean` (false on step entry, true after Accept click)
- Preserve `suggestionsAccepted: true` when navigating back and returning to Step 3
- "Regenerate" button resets to Phase 1 (`suggestionsAccepted: false`) with fresh AI call

**Conversation Context:**
- Refinement requests include: business objective, industry, confirmed assumptions (Step 2), current outcome state
- AI maintains context for multi-turn refinements within the step
- Conversation resets on "Regenerate" or when leaving and re-entering step with fresh data

**UI Consistency with Step 2:**
- Suggestion card styling matches Step 2 assumption cards (bordered container, system headers)
- Accept button matches Step 2 green "Accepted âœ“" style
- Refine input matches Step 2 "Refine assumptions..." input styling
- Loading and error states match Step 2 patterns `M`

17. [x] Security & Guardrails Step â€” Build wizard step 4 for compliance and approval gate configuration:

**Data Sensitivity Classification:**
- Radio buttons: Public, Internal, Confidential, Restricted
- Helper text explaining each level
- Default: Internal

**Compliance Frameworks (checkboxes):**
- SOC 2, HIPAA, PCI-DSS, GDPR, FedRAMP, None/Not specified
- Industry-aware defaults (Healthcare â†’ HIPAA pre-checked, FSI â†’ PCI-DSS + SOC 2)

**Human Approval Gates:**
- Checkbox list of workflow stages where human approval may be required
- Options: "Before external API calls", "Before data modification", "Before sending recommendations", "Before financial transactions"
- Default: None (fully automated demo)

**Guardrail Notes (optional text area):**
- Free-form notes for additional constraints
- On step entry: AI suggests relevant guardrail notes based on context from steps 1-2
- Suggestions are editable, user can modify or clear entirely
- Example placeholder if AI fails: "No PII in demo data, mask account numbers..."

This step is optional â€” "Skip" button available with sensible defaults applied. `S`

18. [x] Agent Design Proposal â€” Create wizard step 5 where model proposes agent team:

**State Structure:**
Add `agentDesign: AgentDesignState` to IdeationState following existing patterns:
```typescript
interface AgentDesignState {
  // AI Proposal
  proposedAgents: ProposedAgent[];
  proposedOrchestration: OrchestrationPattern;
  proposedEdges: ProposedEdge[];
  orchestrationReasoning: string;

  // Accept/Edit State
  proposalAccepted: boolean;
  isLoading: boolean;
  error?: string;

  // Change Detection
  step4Hash?: string;
  aiCalled: boolean;
}

interface ProposedAgent {
  id: string;
  name: string;
  role: string;
  tools: string[];  // AI-generated from Step 1 systems
}

interface ProposedEdge {
  from: string;
  to: string;
  condition?: string;  // For graph pattern
}
```

**Auto-Proposal on Step Entry:**
- Trigger: `triggerAutoSendForStep5()` following Step 3 pattern
- Change detection: Hash of Steps 1-4 inputs
- Send context to Bedrock, request JSON-structured agent team
- Parse response, populate `proposed*` fields

**Display (Phase 1 â€” Before Accept):**
- Card grid: each agent shows name, role, tools as tags
- Orchestration badge: "Graph" / "Swarm" / "Workflow"
- "Why this pattern?" expandable with `orchestrationReasoning`
- Text-based flow summary (NOT visual diagram):
```
  Flow: Planner â†’ Recommender â†’ Output
```

**Actions:**
- "â†» Regenerate" â€” `handleRegenerateAgentProposal()`, clears and re-fetches
- "Accept & Continue" â€” sets `proposalAccepted: true`, proceeds to Step 6
- "Let me adjust..." â€” sets `proposalAccepted: true`, stays on step, shows edit UI (item 19)

**Tool Generation:**
- AI generates tool names based on systems from Step 1
- Format: `{system}_{operation}` (e.g., `sap_get_inventory`, `salesforce_query_accounts`)
- Editable in item 19 `M`

19. [x] Agent Design Refinement â€” Enable editing when "Let me adjust..." selected:

**Transition:**
- Same page, different UI mode (like Step 3's Phase 1 â†’ Phase 2)
- Show "Accepted âœ“" banner (following Step 3 pattern)

**Agent Card Editing:**
- Each agent as editable card with edited flags:
  - `nameEdited`, `roleEdited`, `toolsEdited` per agent
- Fields: Name (text), Role (textarea), Tools (tag input with Ã— remove)
- "Ã— Remove Agent" with confirmation if agent has edges
- "+ Add Agent" opens card with empty fields

**Orchestration Adjustment:**
- Dropdown: graph / swarm / workflow
- Shows AI recommendation badge on original suggestion
- On change: AI suggests updated edges (non-blocking suggestion)

**Edge Editing:**
- Simple table: "From" dropdown â†’ "To" dropdown
- Add/remove edge buttons
- Validation warnings (non-blocking):
  - Orphan agents (no connections)
  - No entry point

**AI Assistance (Optional â€” Deferred):**
- "âœ¨ Suggest tools" button per agent â†’ quick AI call
- "Validate Design" button â†’ AI reviews, shows suggestions in toast

**Confirm:**
- "Confirm Design" copies to `confirmed*` fields, proceeds to Step 6
- Edited flags prevent AI overwrite on back-navigation `L`

20. [x] Orchestration Pattern Help â€” Tooltips on dropdown options explaining each pattern:

**Implementation:**
- Added `title` attributes to orchestration dropdown `<option>` elements
- Hover over any option (graph/swarm/workflow) to see description

**Pattern Descriptions:**
- **graph**: "LLM picks path at runtime based on conditions. Best for: approval gates, decision trees, conditional workflows."
- **swarm**: "Agents hand off autonomously. Best for: complex problem-solving, collaborative analysis, emergent behavior."
- **workflow**: "Fixed DAG with parallel execution. Best for: predictable pipelines, batch processing, strict ordering."

**Deferred:**
- Edge condition labels (Graph-specific)
- Handoff limits (Swarm-specific)
- Parallel group config (Workflow-specific)

21. [x] Mock Data Strategy â€” Build wizard step 6 for AI-generated mock data configuration:

**Auto-Generation on Step Entry:**
- For each tool identified in agent design, model proposes mock data shape:
```json
{
  "tool": "sap_inventory",
  "system": "SAP S/4HANA",
  "operation": "get_stock_levels",
  "mockRequest": {"warehouse_id": "string", "sku_list": "string[]"},
  "mockResponse": {"sku": "string", "quantity": "number", "location": "string"},
  "sampleData": [
    {"sku": "TOMATO-001", "quantity": 150, "location": "Produce-A3"}
  ]
}
```

**Display & Editing:**
- Accordion for each tool with mock definition
- JSON editor for request/response schemas (with syntax highlighting)
- Sample data table with add/edit/delete rows
- "Use customer terminology" toggle: when ON, model regenerates with industry-specific naming from wizard context

**Bulk Actions:**
- "Regenerate All" â€” fresh mock data proposal from model
- "Import Sample Data" â€” upload CSV/JSON to populate sample data tables

**Validation:**
- Warn if any tool missing mock definition
- Warn if sample data empty (demo won't be realistic)

**Output:**
- Mock definitions stored in wizard state
- Used in Phase 4 steering file generation (`integration-landscape.md`) `M`

22. [x] Wizard State Persistence â€” Implement workspace storage for wizard progress so users can resume incomplete ideation sessions:

**Storage:**
- Save wizard state to `.agentify/wizard-state.json` on each step completion
- State includes: current step, all field values, conversation history, agent design, mock data config
- Exclude uploaded files (too large) â€” store file metadata only with "re-upload required" flag

**Resume Flow:**
- On Ideation Wizard open, check for existing `wizard-state.json`
- If found and less than 7 days old: prompt "Resume previous session?" with preview of business objective
- "Resume" â†’ restore state, navigate to last completed step
- "Start Fresh" â†’ delete state file, begin at step 1

**Auto-Save:**
- Debounced save (500ms after last change) within each step
- Explicit save on "Next" button click

**Clear State:**
- "Reset Wizard" command clears state file and restarts
- State automatically cleared when steering files successfully generated (Phase 4) `S`

23. [x] Demo Design Step â€” Build wizard step 7 for capturing demo presentation strategy:

**Key "Aha Moments" (repeatable field group):**
- Moment title: "What should impress the audience?" â€” e.g., "Real-time SAP inventory sync"
- When it occurs: dropdown selecting which agent/tool triggers this moment
- What to say: suggested talking point for presenter

**Demo Persona:**
- Persona name (text): e.g., "Maria, Regional Inventory Manager"
- Persona role (text): e.g., "Reviews morning replenishment recommendations for 12 stores"
- Persona pain point (text): e.g., "Currently spends 2 hours manually checking stock levels"
- AI assist: "Generate Persona" button creates persona based on industry/objective context

**Narrative Flow:**
- Ordered list of demo scenes (drag-to-reorder)
- Each scene: title, description, which agents are highlighted
- "Generate Narrative" button: model proposes scene sequence based on agent design

**Output:**
- Stored in wizard state for `demo-strategy.md` generation in Phase 4 `M`

23.5. [ ] Demo Script Export â€” Add ability to export demo strategy as a presenter-ready markdown file:

**Export Button:**
- "ğŸ“„ Export Demo Script" button in Step 7 UI (near Generate All)
- Disabled until at least one section has content (persona, moments, or scenes)

**Generated Markdown Format:**
- Header with business objective from Step 1
- Demo Persona section: name, role, pain point
- Aha Moments section: numbered list with title, trigger, and talking point as blockquote
- Narrative Flow section: ordered scenes with descriptions and highlighted agents
- Footer with generation timestamp

**File Output:**
- Creates `demo-script.md` in workspace root (or `.agentify/demo-script.md`)
- Auto-opens file in editor after creation
- Overwrites existing file with confirmation if present

**Example Output:**
```md
# Demo Script: Reduce customer support response time by 40%

## Persona
**Maria, Regional Inventory Manager** â€” Reviews morning replenishment recommendations...
Pain Point: Currently spends 2 hours manually checking stock levels

## Aha Moments
### 1. Real-time VIP customer detection
**Trigger:** Ticket Analyzer
> Watch as the system instantly recognizes this is a VIP customer...

## Narrative Flow
### Scene 1: Opening Context
...
```

**Future Enhancement (Pro Tier):**
- PDF export with polished formatting
- PPTX export for slide-ready presentation `S`

24. [x] Generate Step (Wizard Step 8) â€” Build the final wizard step that orchestrates steering file generation and Kiro handoff:

**Pre-Generation Checklist Display:**
- Show read-only summary of all wizard inputs across steps 1-7
- Validation status for each step (green check if complete, warning if optional fields skipped)
- "Edit" button next to each section to jump back to that step

**Generation Progress UI:**
- Checklist with real-time status updates:
  - [ ] Validate wizard inputs
  - [ ] Generate steering files (â†’ Phase 4, Item 28)
  - [ ] Ready for Kiro
- Each item shows spinner while in progress, checkmark on success, X on failure
- Error details expandable if any step fails
- Note: Agentify Power is installed during project initialization, not here

**Actions:**
- "Generate" button â€” triggers the generation sequence
- "Generate & Open in Kiro" button â€” generates then triggers Kiro spec flow (â†’ Phase 4, Item 34)
- Progress is non-blocking â€” user can see what's happening

**Post-Generation:**
- Success state shows generated file list with "Open File" links
- "Start Over" button to begin new ideation session (clears wizard state)
- If not in Kiro IDE, show message directing user to open project in Kiro

**Dependencies:**
- Requires Phase 3 Item 28 (steering generation) and Item 34 (Kiro trigger) for full functionality
- Agentify Power (Items 29-33) is installed at project init, not here
- Can show placeholder/disabled state until Phase 3 is complete `M`

## Phase 3: Kiro Integration & Enforcement

**Implementation Context:**
- **Demo Scope:** This entire extension generates demos with mock integrations - no real system integrations (SAP, Salesforce, etc.)
- **Local Entry:** `main.py` runs locally, triggers the agent workflow
- **Agent Runtime:** Strands agents deploy to AgentCore Runtime via **AgentCore CLI**
- **Tools:** Either inline with agent code OR as Lambda functions (for shared tools across agents)
- **Orchestration:** Steering files describe the pattern (graph/swarm/workflow), agent definitions, edges, and entry point(s)

28.1. [x] Steering Document Prompts â€” Create system prompts for transforming wizard state into Kiro steering markdown:

**Prompt File Location:**
```
resources/prompts/steering/
â”œâ”€â”€ product-steering.prompt.md
â”œâ”€â”€ tech-steering.prompt.md
â”œâ”€â”€ structure-steering.prompt.md
â”œâ”€â”€ customer-context-steering.prompt.md
â”œâ”€â”€ integration-landscape-steering.prompt.md
â”œâ”€â”€ security-policies-steering.prompt.md
â”œâ”€â”€ demo-strategy-steering.prompt.md
â””â”€â”€ agentify-integration-steering.prompt.md
```

**Each Prompt Defines:**
- Expected markdown structure and sections for that document
- What the document is for (Kiro steering context)
- Formatting guidelines and examples
- JSON input schema it expects from wizard state

**State Mapping Per Document:**
| Document | Wizard State Sections Used |
|----------|---------------------------|
| `product.md` | businessObjective, industry, outcome (primaryOutcome, successMetrics, stakeholders) |
| `tech.md` | agentDesign (agents, orchestration, edges), securityGuardrails (for policy mapping) |
| `structure.md` | agentDesign.confirmedAgents (for folder names), mockData.mockDefinitions (for tools) |
| `customer-context.md` | industry, systems, aiGapFillingState.confirmedAssumptions |
| `integration-landscape.md` | systems, agentDesign (for shared tools analysis), mockData |
| `security-policies.md` | securityGuardrails (sensitivity, frameworks, approvalGates) |
| `demo-strategy.md` | demoStrategy (ahaMoments, persona, narrativeScenes) |
| `agentify-integration.md` | agentDesign.confirmedAgents (agent IDs), orchestration pattern |

**AgentCore Features Guidance (in tech-steering.prompt.md):**
Prompt should guide Kiro on which AgentCore features to use:
- **Runtime**: Deploy agents via AgentCore CLI (serverless, session isolation)
- **Gateway**: Register shared Lambda tools (auto-converts to MCP-compatible)
- **Policy**: Map Step 4 guardrails to Cedar policies (approval gates â†’ boundaries)
- **Observability**: Agentify DynamoDB events (powers Demo Viewer panel)
- **Memory/Identity/Evaluations**: Optional, note when useful

**Shared Tools Analysis (in integration-landscape-steering.prompt.md):**
Prompt should instruct model to:
- Identify duplicate tools across agents (e.g., multiple agents use `databricks_query`)
- Flag shared tools for Lambda deployment + Gateway registration
- Keep per-agent tools inline with agent code
- Output as markdown tables with "Used By" column

**agentify-integration.md Content:**
- Event emission contract (DynamoDB schema for workflow events)
- Agent IDs for OpenTelemetry trace correlation
- CLI invocation pattern for Demo Viewer (`python main.py --workflow-id {id}`)
- Required decorators/instrumentation patterns `M`

28.2. [x] Steering Generation Service â€” Implement service that generates steering files using prompts from Item 28.1:

**Service Interface:**
```typescript
// src/services/steeringGenerationService.ts
interface GenerationResult {
  success: boolean;
  files: GeneratedFile[];
  errors?: { file: string; error: string }[];
}

interface GeneratedFile {
  fileName: string;
  filePath: string;
  content: string;
  status: 'created' | 'failed';
}

class SteeringGenerationService {
  async generateSteeringFiles(state: IdeationState): Promise<GenerationResult>;
  async generateDocument(promptName: string, context: object): Promise<string>;
}
```

**Generation Flow:**
1. Load all prompt files from `resources/prompts/steering/`
2. Extract relevant state sections for each document (per mapping in 28.1)
3. Generate all 8 documents in parallel using Bedrock
4. Return results with content and status per file

**Per-Document Generation:**
```typescript
private async generateDocument(promptName: string, context: object): Promise<string> {
  const systemPrompt = await this.loadPrompt(`steering/${promptName}.prompt.md`);
  return this.bedrockService.generate({
    systemPrompt,
    userMessage: JSON.stringify(context, null, 2),
  });
}
```

**Why Parallel Generation:**
- 8 independent documents with no cross-dependencies
- Reduces total generation time from ~40s (sequential) to ~5-8s (parallel)
- Individual failures don't block other documents

**Error Handling:**
- Catch per-document generation errors
- Continue generating remaining documents on failure
- Return partial results with error details for failed documents
- Step 8 UI handles display of partial success

**Relationship to Step 8:**
This service replaces the stub service from Item 24. Step 8 calls this service and handles UI/progress display. Service is responsible only for content generation, not file I/O. `M`

28.3. [x] Steering File Writer & Step 8 Integration â€” Write generated steering files to workspace and integrate with Step 8 UI:

**File Writing:**
- Create `.kiro/steering/` directory if not exists
- Write each generated document from Item 28.2 to corresponding file
- Emit progress events for Step 8 UI updates

**Conflict Handling:**
- Check if `.kiro/steering/` directory exists with files
- If exists, prompt: "Overwrite existing steering files?"
- Options: "Overwrite", "Backup & Overwrite", "Cancel"
- "Backup & Overwrite" copies existing to `.kiro/steering.backup-{timestamp}/`

**Step 8 Integration:**
- Replace stub service calls with real `SteeringGenerationService`
- Update progress UI to show per-file generation status
- Remove `isPlaceholderMode` flag and "Preview mode" indicator
- On success: show generated file list with "Open File" links
- On partial failure: show which files succeeded/failed with retry option

**Post-Generation Actions:**
- Clear wizard state (per Item 22) on full success only
- Keep wizard state on partial failure (allow retry)
- "Open in Kiro" button reveals `.kiro/steering/` folder
- If in Kiro IDE: TODO placeholder for `kiro.startSpecFlow` command (Item 34)

**Validation Before Generation:**
- Verify required wizard steps have content (Steps 1, 3, 5 minimum)
- Show validation errors in Step 8 summary cards
- Block generation if critical steps incomplete

**Files Written:**
```
.kiro/steering/
â”œâ”€â”€ product.md
â”œâ”€â”€ tech.md
â”œâ”€â”€ structure.md
â”œâ”€â”€ customer-context.md
â”œâ”€â”€ integration-landscape.md
â”œâ”€â”€ security-policies.md
â”œâ”€â”€ demo-strategy.md
â””â”€â”€ agentify-integration.md
```

**Demo Script Note:**
`demo-script.md` (Item 23.5) is a separate presenter-focused export to workspace root. `demo-strategy.md` here is Kiro steering for code generation â€” different purpose, different audience. `M`

28.4. [x] Implementation Roadmap Generation (Phase 2) â€” Generate `roadmap.md` from steering files with Kiro usage guidance:

**Trigger:** "Generate Roadmap" button appears in Step 8 UI after Phase 1 steering files are written successfully

**Prompt File:** `resources/prompts/steering/roadmap-steering.prompt.md` (already created)

**Input Context (loaded from generated steering files):**
- `.kiro/steering/tech.md` â€” AgentCore architecture, deployment patterns
- `.kiro/steering/structure.md` â€” Code organization, Strands patterns
- `.kiro/steering/integration-landscape.md` â€” Tools per agent, mock data schemas
- `.kiro/steering/agentify-integration.md` â€” Event contracts, CLI interface

**Roadmap Generation Logic:**
1. Load all 4 input steering files
2. Pass file contents as XML blocks to `roadmap-steering.prompt.md`
3. Generate roadmap via Bedrock
4. Write output to `.kiro/steering/roadmap.md`

**Roadmap Output Structure:**
```markdown
# Implementation Roadmap

## How to Use This Roadmap

This roadmap contains items, each with a prompt for Kiro IDE. Follow this workflow:

1. Open Kiro IDE in this project
2. Copy **Item 1** prompt text (everything in the code block)
3. Paste into Kiro chat â€” Kiro generates spec.md, then requirements, design, tasks, and implements
4. Verify the acceptance criteria on the implemented code
5. Move to **Item 2**, repeat until all items complete

Each item builds on previous ones. Complete them in order.

---

## Architecture Context

> **Include this understanding when reviewing generated code:**
>
> - Agents deploy to **Amazon Bedrock AgentCore Runtime** via AgentCore CLI
> - Only `agents/main.py` runs locally â€” it orchestrates remote agents
> - Use **Strands SDK**: `from strands import Agent, tool`
> - All integrations are **mock tools** (this is a demo system)
> - Emit events to DynamoDB + stdout for Demo Viewer visualization
>
> If generated code runs agents locally or uses real integrations, request corrections.

---

## Item 1: Mock Data Infrastructure
...

## Item 2: {Agent Name} Agent
...
```

**Per-Item Format (enforced by prompt):**
```markdown
## Item N: {Name}

**Purpose:** {one-line description}

**Depends on:** {Item numbers that must be complete first}

**Files to be created:**
- `{path}` â€” {description}

**Prompt for Kiro â€” Copy everything in the code block below and paste into Kiro chat:**

\`\`\`
{Full prompt text with CRITICAL ARCHITECTURE block embedded}
\`\`\`

**Acceptance Criteria (verify after Kiro implements):**
- [ ] {Specific verification step}
- [ ] {Another verification step}
```

**Critical: Architecture Context Embedding**
Every prompt MUST include this block at the top:
```
## CRITICAL ARCHITECTURE â€” READ BEFORE GENERATING CODE

This is an Agentify demo project. Follow these rules strictly:

1. **Agent Deployment**: Agents deploy to Amazon Bedrock AgentCore Runtime
   via `agentcore deploy`. They run REMOTELY, not locally.

2. **Local Orchestrator Only**: Only `agents/main.py` runs locally.
   It orchestrates by calling remote agents.

3. **Strands SDK**: Use `from strands import Agent, tool`

4. **Mock Tools**: All integrations are mocks returning realistic fake data.

5. **Event Emission**: Emit events per .kiro/steering/agentify-integration.md
```

**Item Sequence (generated dynamically from steering files):**
1. **Item 1: Mock Data Infrastructure** â€” Shared mock data files + utilities
2. **Items 2-N: One per agent** â€” Each agent with inline tools, deploys to AgentCore
3. **Final Item: Main Orchestrator** â€” Local `main.py` with CLI contract

**Phase 2 UI (Step 8):**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Phase 2: Implementation Roadmap                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  [Generate Roadmap]                                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â”‚  Status: [â³] Generating roadmap.md...                      â”‚
â”‚                                                             â”‚
â”‚  Once complete, the roadmap will guide you through:        â”‚
â”‚                                                             â”‚
â”‚  â€¢ Item 1: Mock Data Infrastructure                        â”‚
â”‚  â€¢ Item 2: {Agent A} Agent                                 â”‚
â”‚  â€¢ Item 3: {Agent B} Agent                                 â”‚
â”‚  â€¢ Item N: Main Orchestrator                               â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Post-Generation UI (Success State):**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Phase 2: Implementation Roadmap                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  âœ… roadmap.md generated successfully                       â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                     â”‚   â”‚
â”‚  â”‚  ğŸ“‹ How to implement with Kiro:                     â”‚   â”‚
â”‚  â”‚                                                     â”‚   â”‚
â”‚  â”‚  1. Open roadmap.md                                 â”‚   â”‚
â”‚  â”‚  2. Copy the prompt from Item 1                     â”‚   â”‚
â”‚  â”‚  3. Paste into Kiro chat                            â”‚   â”‚
â”‚  â”‚  4. Kiro creates spec.md â†’ requirements â†’ design    â”‚   â”‚
â”‚  â”‚     â†’ tasks â†’ implementation                        â”‚   â”‚
â”‚  â”‚  5. Verify the acceptance criteria                  â”‚   â”‚
â”‚  â”‚  6. Repeat with Item 2, 3, ... in order            â”‚   â”‚
â”‚  â”‚                                                     â”‚   â”‚
â”‚  â”‚  Each item builds on previous ones.                 â”‚   â”‚
â”‚  â”‚  Complete them sequentially.                        â”‚   â”‚
â”‚  â”‚                                                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â”‚  [Open roadmap.md]  [Open Folder in Kiro]  [Start Over]    â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Error Handling:**
- If any required steering file missing, show error with "Regenerate Steering Files" button
- If roadmap generation fails, show retry button with error details
- Partial generation not supported â€” roadmap is all-or-nothing

**Files Written:**
- `.kiro/steering/roadmap.md`

**Integration with Step 8 Flow:**
- Phase 1 button: "Generate Steering Files" (existing from 28.3)
- Phase 1 complete â†’ Phase 2 section appears
- Phase 2 button: "Generate Roadmap"
- Phase 2 complete â†’ Usage instructions + action buttons appear
- "Start Over" clears wizard state and returns to Step 1 `M`

28.5. [x] CDK Infrastructure Bundling & Extraction â€” Replace CloudFormation SDK deployment with bundled CDK infrastructure:

**File Extraction on "Initialize Project":**
- Extract bundled `resources/cdk/` to `{workspace}/cdk/` (full CDK project with NetworkingStack + ObservabilityStack)
- Extract bundled `resources/scripts/` to `{workspace}/scripts/` (setup.sh, destroy.sh, Dockerfile template)
- Auto-open `cdk/README.md` in editor with deployment instructions

**User-Driven Deployment:**
- User runs `./scripts/setup.sh --region {region}` manually
- setup.sh outputs to `.agentify/infrastructure.json` (deployment info)
- Clear instructions include CDK bootstrap (first-time), deployment command, cost estimate (~$32/mo)

**Config Architecture:**
- Keep separate files: `infrastructure.json` (deployment outputs), `config.json` (extension settings)
- Extension reads from `infrastructure.json` when present for DynamoDB table name/region

**Code Cleanup:**
- Remove `src/services/cloudFormationService.ts`
- Remove `infrastructure/dynamodb-table.yaml`
- Remove `infrastructure/` folder
- Update `initializeProject.ts` to use file extraction instead of SDK calls

**Bundling:**
- Ensure `resources/cdk/` and `resources/scripts/` included in VSIX package
- Add `cdk/README.md` with comprehensive deployment instructions `M`

28.6. [ ] Shared Utilities Bundling â€” Bundle generic observability infrastructure as pre-existing resources (like CDK), not Kiro-generated:

**Background:**
The `agents/shared/` module contains generic observability infrastructure that is identical across all Agentify demos:
- `instrumentation.py` â€” `@instrument_tool` decorator, context management (`set_instrumentation_context`, `clear_instrumentation_context`)
- `dynamodb_client.py` â€” Fire-and-forget event persistence to DynamoDB, query for Demo Viewer
- `__init__.py` â€” Module exports with integration examples

This code is 100% generic (no hardcoded agent names, no tool-specific logic, no domain assumptions) and should be bundled like CDK infrastructure rather than regenerated by Kiro for each project.

**New Resources to Create:**
```
resources/agents/shared/
â”œâ”€â”€ __init__.py              # Module exports with integration examples
â”œâ”€â”€ instrumentation.py       # @instrument_tool decorator, context management
â”œâ”€â”€ dynamodb_client.py       # Fire-and-forget event persistence
â””â”€â”€ utils/
    â””â”€â”€ __init__.py          # Placeholder for future utilities
```

Source: Copy validated implementation from test-agentify project after Kiro roadmap validation.

**Extension Changes:**

1. **`src/services/resourceExtractionService.ts`:**
   - Add `agents` folder to extraction alongside `cdk` and `scripts`
   - Ensure Python files get proper permissions

2. **`src/commands/initializeProject.ts`:**
   - Extract `resources/agents` â†’ `workspace/agents` during project initialization
   - Creates `agents/shared/` with pre-bundled utilities

**Steering Prompt Updates (4 files):**

| File | Change |
|------|--------|
| `agentify-integration-steering.prompt.md` | Remove full module implementations (~300 lines for instrumentation.py and dynamodb_client.py). Add "Pre-Bundled Module" section. Show import patterns only: `from agents.shared.instrumentation import instrument_tool, set_instrumentation_context` |
| `structure-steering.prompt.md` | Add explicit note that `agents/shared/` is pre-bundled. Mark as "(pre-bundled - DO NOT MODIFY)" in directory structure. |
| `tech-steering.prompt.md` | Clarify in tool deployment section that shared instrumentation already exists. Add note: "The `agents.shared` module is pre-bundled. Import it, don't recreate it." |
| `roadmap-steering.prompt.md` | Remove "Shared Utilities" as a generated roadmap item since it's pre-bundled. Roadmap should start with Gateway Lambda handlers or first agent implementation. |

**No changes needed:**
- `product-steering.prompt.md` â€” No implementation details
- `customer-context-steering.prompt.md` â€” No implementation details
- `demo-strategy-steering.prompt.md` â€” No implementation details
- `security-policies-steering.prompt.md` â€” No implementation details
- `integration-landscape-steering.prompt.md` â€” References existing patterns

**Documentation Update:**

Update `agent-os/product/demo-development-workflow.md`:
- Add `agents/shared/` to project structure diagram with "(pre-bundled)" annotation
- Update "Key distinction" section: `agents/shared/` = Pre-bundled utilities (DO NOT MODIFY)
- Update summary table: "Shared utilities" created by "Agentify (bundled)" not "Kiro"

**Updated Project Structure (End State):**
```
project/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ shared/                 # Pre-bundled (DO NOT MODIFY)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ instrumentation.py  # @instrument_tool decorator
â”‚   â”‚   â”œâ”€â”€ dynamodb_client.py  # Event persistence
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # Kiro generated - local orchestrator
â”‚   â”œâ”€â”€ analyzer.py             # Kiro generated - agent handlers
â”‚   â””â”€â”€ ...
â”œâ”€â”€ cdk/                        # Pre-bundled (DO NOT MODIFY stacks/)
â””â”€â”€ scripts/                    # Pre-bundled
```

**Benefits:**
1. **Consistency** â€” Every demo gets identical, tested observability infrastructure
2. **No regeneration** â€” Kiro focuses on agent logic, not infrastructure
3. **Demo Viewer compatibility** â€” Guaranteed event schema match with extension
4. **Faster iteration** â€” Improvements to shared utilities benefit all projects

**Validation (Before Implementation):**
- Complete Kiro roadmap in test-agentify project
- Verify shared utilities work correctly with generated agents
- Confirm no project-specific modifications needed
- Validate Demo Viewer correctly consumes events from bundled utilities

**Implementation Steps:**
1. Copy validated `test-agentify/agents/shared/*` â†’ `agentify/resources/agents/shared/`
2. Update `resourceExtractionService.ts` to extract `agents` folder
3. Update `initializeProject.ts` to include agents in extraction
4. Update 4 steering prompt files (see table above)
5. Update `demo-development-workflow.md` documentation
6. Test: Initialize new project, verify `agents/shared/` extracted correctly
7. Test: Run Kiro roadmap on new project, verify agents import from pre-bundled shared `M`

29. [ ] Agentify Power Package â€” Create Kiro Power that bundles steering guidance and enforcement hooks. **This is a generic package installed during project initialization (extends Item 4), not per-ideation.** Ensures all agent code follows Agentify patterns from day one:

**Power Structure:**
```
agentify-power/
â”œâ”€â”€ POWER.md              # Steering for agentic workflow development
â””â”€â”€ hooks/
    â”œâ”€â”€ observability-enforcer.kiro.hook
    â”œâ”€â”€ cli-contract-validator.kiro.hook
    â””â”€â”€ mock-tool-pattern.kiro.hook
```

**POWER.md Content:**
- Best practices for Strands agent development
- Event emission patterns (reference `agentify-integration.md`)
- CLI contract requirements (Agentify CLI for local testing)
- AgentCore CLI deployment patterns (deploy to Bedrock AgentCore Runtime)
- Mock tool implementation guidelines (demo scope)
- Common pitfalls and solutions

**Activation Keywords:**
- "agent", "workflow", "Strands", "orchestrator", "demo", "multi-agent"

**Distribution:**
- Bundled with Agentify extension in `resources/agentify-power/`
- Can be published to Kiro community powers for standalone use `M`

30. [ ] Observability Enforcement Hook â€” Create `observability-enforcer.kiro.hook`:

**Trigger:**
- Event: `fileSaved`
- Pattern: `agents/*.py`

**Validation Rules:**
- Check for `emit_stdout_event()` or equivalent calls in agent functions
- Verify `workflow_id` and `trace_id` passed to all event emissions
- Check `graph_structure` emitted before `node_start` events
- Verify terminal event (`workflow_complete` or `workflow_error`) emitted

**Hook Prompt:**
```
Review this agent file for Agentify observability compliance.
Reference: .kiro/steering/agentify-integration.md

Check:
1. All agent functions emit node_start/node_stop events
2. Tool calls emit tool_call events to DynamoDB
3. workflow_id and trace_id included in all events
4. Terminal event emitted on completion/error

Suggest fixes for any missing observability code.
```

**Output:**
- Inline suggestions for missing event emissions
- Warning if no observability code detected `S`

31. [ ] CLI Contract Validation Hook â€” Create `cli-contract-validator.kiro.hook`:

**Trigger:**
- Event: `fileSaved`
- Pattern: `agents/main.py`

**Validation Rules:**
- Check `argparse` setup exists
- Verify `--prompt` argument defined and required
- Verify `--workflow-id` argument defined and required
- Verify `--trace-id` argument defined and required
- Check `os.environ.get('AGENTIFY_TABLE_NAME')` present
- Check `os.environ.get('AGENTIFY_TABLE_REGION')` present

**Hook Prompt:**
Validate this main.py entry point against Agentify CLI contract.
Reference: .kiro/steering/agentify-integration.md Section 1
Required CLI arguments: --prompt, --workflow-id, --trace-id
Required env vars: AGENTIFY_TABLE_NAME, AGENTIFY_TABLE_REGION
Flag any missing arguments or environment variable reads.
Suggest argparse setup if not present.
`````S`

32. [ ] Mock Tool Pattern Hook â€” Create mock-tool-pattern.kiro.hook (validates mock integrations for demo purposes, not real integrations):

Trigger:

Event: fileCreated
Pattern: tools/*.py

Validation Rules:

Check for Strands @tool decorator on functions
Verify function has docstring (used by Strands for tool description)
Check return type annotation present
Validate mock data structure if integration-landscape.md exists

Hook Prompt:
Review this new tool file for Strands SDK compliance.
Reference: .kiro/steering/integration-landscape.md for expected mock data shapes

Check:
1. @tool decorator present on tool functions
2. Docstring describes what the tool does
3. Type hints on parameters and return value
4. Mock response matches schema in integration-landscape.md

Suggest improvements for realistic mock behavior.
`````S`

33. [ ] Power Installation Integration â€” **Extend Project Initialization (Item 4)** to install Agentify Power during "Agentify: Initialize Project" command:

**Installation Flow:**
1. After writing steering files, check if Agentify Power installed
2. If not installed, copy from `resources/agentify-power/` to `.kiro/powers/agentify/`
3. Register power in `.kiro/powers/manifest.json`

**Power Manifest:**
```json
{
  "powers": [
    {
      "name": "agentify",
      "path": "./agentify",
      "activationKeywords": ["agent", "workflow", "Strands", "orchestrator", "demo"]
    }
  ]
}
```

**Verification:**
- Validate hooks are syntactically correct
- Show notification: "Agentify Power installed - enforcement hooks active" `S`

34. [ ] Kiro Spec Trigger â€” Implement seamless handoff from Ideation Wizard to Kiro spec mode:

**Pre-Flight Checks:**
1. Verify all steering files exist in `.kiro/steering/`
2. Verify Agentify Power installed (item 33)
3. Verify `.agentify/config.json` exists with valid DynamoDB config

**Trigger Flow:**
1. User clicks "Generate Code with Kiro" button in wizard
2. Run pre-flight checks, show errors if any fail
3. Build initial prompt from wizard context:
```
   Create a multi-agent workflow based on the steering files in .kiro/steering/.

   Business objective: {from product.md}
   Orchestration pattern: {from tech.md}
   Agents: {from agent design}

   Start with agents/main.py following the CLI contract in agentify-integration.md.
```
4. Execute Kiro command: `kiro.startSpecFlow` with prompt
5. Show confirmation: "Kiro spec mode started. Enforcement hooks are active."

**VS Code Fallback:**
- Detect if running in VS Code (not Kiro) via `vscode.env.appName`
- Show message: "Code generation requires Kiro IDE. Steering files have been generated in .kiro/steering/. Open this project in Kiro to continue."
- Offer "Learn More" link to Kiro download page `S`

## Phase 4: Visual Polish

25. [ ] Agent Graph Visualization â€” Add React Flow visualization to Demo Viewer with custom node components showing agent status (pending/running/completed/failed), animated edges during data flow, auto-layout via dagre/elkjs, and pattern-specific layouts:

**Node Components:**
- Custom React Flow node for each agent
- Status indicator: gray (pending), blue pulse (running), green (completed), red (failed)
- Agent name and role displayed
- Tool call count badge

**Edge Styling:**
- Animated dashes during active data flow
- Edge labels for Graph pattern conditions
- Bidirectional arrows for Swarm handoffs

**Layout Algorithms:**
- **Graph**: Dagre top-to-bottom DAG layout with conditional edge routing
- **Swarm**: Force-directed peer-to-peer layout (circular for small graphs)
- **Workflow**: ELKjs layered layout with parallel execution lanes

**Initialization:**
- Read `graph_structure` event from stdout to build initial topology
- Fall back to agent design from `.agentify/config.json` if no event received

**Interaction:**
- Click node to highlight in Execution Log
- Zoom/pan controls
- "Fit to view" button `L`

26. [ ] Graph Animation â€” Implement real-time graph updates from stdout events with smooth transitions:

**Event Handling:**
- `node_start` â†’ transition node to "running" state with blue pulse animation
- `node_stream` â†’ show streaming indicator on node (optional: token count)
- `node_stop` â†’ transition to "completed" (green) or "failed" (red) based on status
- `handoff` â†’ animate edge between source and target nodes

**Transitions:**
- CSS transitions for color changes (300ms ease)
- Edge animation: dashed line "flow" effect during active transfer
- Completion ripple effect on node finish

**Timing:**
- Debounce rapid updates (batch within 50ms window)
- Queue animations to prevent visual chaos during parallel execution

**State Sync:**
- Graph state synced with Execution Log scroll position
- Clicking log entry highlights corresponding node `M`

27. [ ] Enhanced Log Formatting â€” Improve Execution Log panel with advanced formatting and filtering:

**Collapsible Sections:**
- Group events by agent (collapsible agent sections)
- Tool calls collapsed by default, expandable to show input/output
- "Expand All" / "Collapse All" toolbar buttons

**Syntax Highlighting:**
- JSON payloads with syntax highlighting (use existing `tokenizeJson()`)
- SQL queries highlighted if detected in tool input
- Markdown rendering for text content

**Filtering:**
- Filter dropdown: "All Events", "Agent Events Only", "Tool Calls Only", "Errors Only"
- Agent filter: multi-select to show only specific agents
- Search box: text search across event content

**Performance:**
- Virtual scrolling for large event lists (>100 events)
- Lazy render expanded payload content `M`

## Phase 5: Templates and Patterns

38. [ ] Industry Template Framework â€” Build template system for storing and loading pre-built agent patterns with metadata `M`

39. [ ] Retail Industry Template â€” Create agent patterns for common retail scenarios: inventory optimization, customer service, demand forecasting `M`

40. [ ] FSI Industry Template â€” Create agent patterns for financial services: fraud detection, customer onboarding, risk assessment `M`

41. [ ] Healthcare Industry Template â€” Create agent patterns for healthcare: patient scheduling, claims processing, clinical decision support `M`

42. [ ] Manufacturing Industry Template â€” Create agent patterns for manufacturing: predictive maintenance, quality control, supply chain optimization `M`

43. [ ] Value Map Template Framework â€” Build storage and loading system for value map templates with metadata schema including recommended orchestration pattern `M`

44. [ ] Common Value Map Templates â€” Create templates for common value maps, each with suggested agent teams and recommended Strands pattern: Cost Reduction (typically Workflow for deterministic optimization pipeline), Revenue Growth (typically Graph for conditional customer journey routing), Operational Efficiency (typically Workflow for parallel automation tasks), Customer Experience (typically Swarm for collaborative issue resolution), Risk Mitigation (typically Graph for decision trees with approval gates) `L`

45. [ ] Demo Script Generator â€” Create AI-powered talking points generator that produces demo narrative aligned with business objective and agent design `M`

## Phase 6: Enterprise Features

46. [ ] Demo Library Storage â€” Implement cloud storage for saving completed demos with metadata, tags, and search capability `L`

47. [ ] Demo Sharing â€” Add team sharing functionality with permissions and version tracking for collaborative demo development `M`

48. [ ] Demo Analytics â€” Build tracking for demo usage metrics: runs, customer reactions, conversion correlation `L`

49. [ ] Multi-Region Deployment â€” Add region selector and deployment automation for production deployments in us-east-1, us-west-2, eu-west-1 `M`

50. [ ] Demo Export â€” Create export functionality for packaging demos as standalone artifacts for offline or customer-site execution `M`

---

## Notes

- Order items by technical dependencies and product architecture
- Each item should represent an end-to-end functional and testable feature
- Single Agentify extension with two webview panels: Demo Viewer (runtime visualization) and Ideation Wizard (design-time workflow)
- **Single deployment model**: Orchestration always runs locally via `agents/main.py`, which calls agents deployed to Bedrock AgentCore. There are no separate "local" vs "AgentCore" deployment modes.
- **Dual-mode event streaming** (not deployment):
  - **stdout streaming**: Real-time JSON lines from subprocess for graph visualization
  - **DynamoDB polling**: Persistent storage for tool calls and historical replay
- **Hybrid identity**: Each run has short `workflow_id` (wf-xxx for UI/DynamoDB) + OTEL `trace_id` (32-char hex for X-Ray correlation)
- **main.py generation**: The orchestration entry point is generated by Kiro spec-driven development following patterns in `agentify-integration.md`, not created by the Agentify extension
- Strands SDK provides native OpenTelemetry support via `StrandsTelemetry` - no custom decorator package needed
- Project config stored in `.agentify/config.json`, Kiro steering in `.kiro/steering/agentify-integration.md`
- "Agentify: Initialize Project" command must run before using the extension
- CloudFormation templates in `infrastructure/` are bundled with the extension for automated deployment
- Phase 1 establishes core infrastructure before building features that depend on it
- Phase 2 AI features require Bedrock integration from earlier items
- Phase 3 Kiro integration depends on wizard outputs from Phase 2
- Phase 4 Visual Polish can be deferred until after Kiro integration is working
- Phase 5-6 are enhancement phases that can be prioritized based on customer feedback
- **Agentify Power**: Bundles steering guidance and enforcement hooks into a Kiro Power package that activates on-demand during agent development
- **Enforcement Hooks**: Automatically validate generated code follows Agentify patterns (event emission, CLI contract, mock tool structure) as files are saved
- Hooks reference steering files for validation rules, creating a closed loop between documentation and enforcement

## Technical References

- Strands Agents SDK: https://strandsagents.com/latest/
- Multi-agent patterns documentation: https://strandsagents.com/latest/documentation/docs/user-guide/concepts/multi-agent/multi-agent-patterns/
- Strands Observability/Traces: https://strandsagents.com/latest/documentation/docs/user-guide/observability-evaluation/traces/
- OpenTelemetry Context Propagation: https://opentelemetry.io/docs/concepts/context-propagation/
- W3C Trace Context (traceparent header): https://www.w3.org/TR/trace-context/
- Kiro Powers: https://kiro.dev/powers/ and https://kiro.dev/docs/powers/
- Kiro Hooks: https://kiro.dev/docs/hooks/ and https://kiro.dev/docs/hooks/types/
- Three orchestration patterns supported:
  - **Graph**: Deterministic structure with LLM-driven path selection, supports cycles, conditional edges
  - **Swarm**: Autonomous agent collaboration with emergent handoffs, supports cycles, shared context
  - **Workflow**: Fixed DAG execution with automatic parallelization, no cycles, task dependencies
