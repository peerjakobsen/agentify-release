/**
 * Configuration types for Agentify projects
 * Defines the schema for .agentify/config.json
 *
 * Agentify uses a single deployment model: local subprocess execution.
 * The orchestration runs locally via agents/main.py, which calls agents
 * deployed to Bedrock AgentCore via Strands SDK.
 */

/**
 * Project configuration
 * Defines the business context for the Agentify project
 */
export interface ProjectConfig {
  /**
   * Human-readable project name
   * @example "Customer Service Agent"
   */
  name: string;

  /**
   * Customer value map describing the project's purpose
   * @example "Reduce customer wait times and improve satisfaction"
   */
  valueMap: string;

  /**
   * Industry vertical for domain-specific templates and prompts
   * @example "retail", "fsi", "healthcare", "tech"
   */
  industry: string;
}

/**
 * DynamoDB infrastructure configuration
 * Specifies the table used for workflow event storage
 */
export interface DynamoDbInfrastructureConfig {
  /**
   * Name of the DynamoDB table
   * @example "agentify-workflow-events"
   */
  tableName: string;

  /**
   * ARN of the DynamoDB table
   * @example "arn:aws:dynamodb:us-east-1:123456789012:table/agentify-workflow-events"
   */
  tableArn: string;

  /**
   * AWS region where the table is deployed
   * @example "us-east-1"
   */
  region: string;
}

/**
 * Infrastructure configuration
 * Contains all infrastructure-related settings
 *
 * Note: For new projects, dynamodb is optional because it will be
 * populated from infrastructure.json after user runs setup.sh.
 * For backward compatibility, existing projects with dynamodb in
 * config.json are still supported.
 */
export interface InfrastructureConfig {
  /**
   * DynamoDB configuration for workflow events
   * Optional for new projects - will be read from infrastructure.json after deployment
   */
  dynamodb?: DynamoDbInfrastructureConfig;

  /**
   * Bedrock configuration for AI model integration
   */
  bedrock: BedrockInfrastructureConfig;
}

/**
 * Agent definition within a workflow
 * Represents a single agent node in the workflow graph
 */
export interface AgentDefinition {
  /**
   * Unique identifier for the agent within the workflow
   * @example "research-agent"
   */
  id: string;

  /**
   * Human-readable display name
   * @example "Research Agent"
   */
  name: string;

  /**
   * Description of the agent's role in the workflow
   * @example "Gathers and analyzes relevant information"
   */
  role: string;
}

/**
 * Edge definition connecting agents in the workflow
 * Represents data flow between agent nodes
 */
export interface EdgeDefinition {
  /**
   * ID of the source agent node
   */
  from: string;

  /**
   * ID of the target agent node
   */
  to: string;
}

/**
 * Orchestration pattern for workflow execution
 * - 'graph': Directed acyclic graph with explicit edges
 * - 'swarm': Dynamic agent coordination
 * - 'workflow': Sequential step-by-step execution
 */
export type OrchestrationPattern = 'graph' | 'swarm' | 'workflow';

/**
 * Workflow configuration
 * Defines the workflow structure and agent composition
 *
 * The Demo Viewer spawns the entry script as a subprocess with CLI args:
 * --prompt, --workflow-id, --trace-id
 */
export interface WorkflowConfig {
  /**
   * Path to the entry script relative to workspace root
   * Generated by Kiro spec-driven development
   * @example "agents/main.py"
   */
  entryScript: string;

  /**
   * Path to the Python interpreter
   * @example ".venv/bin/python" or "python3"
   */
  pythonPath: string;

  /**
   * Orchestration pattern for the workflow
   * Determines how agents coordinate:
   * - 'graph': Deterministic structure with LLM-driven path selection
   * - 'swarm': Autonomous agent collaboration with emergent handoffs
   * - 'workflow': Fixed DAG execution with automatic parallelization
   */
  orchestrationPattern: OrchestrationPattern;

  /**
   * List of agents that compose the workflow
   */
  agents: AgentDefinition[];

  /**
   * Edges defining data flow between agents (for graph patterns)
   */
  edges: EdgeDefinition[];
}

/**
 * AWS configuration for credential and profile management
 * Allows project-level override of AWS profile selection
 */
export interface AwsConfig {
  /**
   * AWS CLI profile name to use for credentials
   * When specified, this profile is passed to the AWS SDK credential provider chain.
   * When omitted, the SDK uses default behavior (AWS_PROFILE env var or 'default' profile).
   * @example "my-dev-profile"
   */
  profile?: string;

  /**
   * AWS region selected during initialization
   * Stored for user reference
   * @example "us-east-1"
   */
  region?: string;
}

/**
 * Bedrock configuration for AI model integration
 * Controls the model and region used for ideation assistance
 */
export interface BedrockInfrastructureConfig {
  /**
   * Bedrock model ID for API calls
   * @example "global.anthropic.claude-sonnet-4-5-20250929-v1:0"
   */
  modelId: string;

  /**
   * AWS region for Bedrock API calls
   * @example "us-east-1"
   */
  region: string;
}

/**
 * Configuration for observability features
 */
export interface ObservabilityConfig {
  /**
   * AWS X-Ray console URL template
   * Supports {region} and {trace_id} placeholders
   * @example "https://{region}.console.aws.amazon.com/xray/home?region={region}#/traces/{trace_id}"
   */
  xrayConsoleUrl?: string;
}

/**
 * Routing configuration for Haiku-based routing decisions
 * Controls the lightweight router model used for Graph and Swarm patterns
 *
 * The Haiku router provides fast, cost-effective routing decisions (~10x cheaper,
 * ~3x faster than Sonnet) while maintaining flexibility for complex workflows.
 */
export interface RoutingConfig {
  /**
   * Enable Haiku-based routing for Graph and Swarm patterns
   * When enabled, uses Claude Haiku for routing decisions before falling back
   * to existing strategies (agent decision, classification, static routes).
   * @default false (opt-in to avoid surprise Bedrock costs)
   */
  useHaikuRouter: boolean;

  /**
   * Bedrock model ID for the router
   * Uses global inference profile for cross-region compatibility.
   * Can be overridden for SCP-restricted environments.
   * @default "global.anthropic.claude-haiku-4-5-20251001-v1:0"
   */
  routerModel: string;

  /**
   * Enable silent fallback to existing routing strategies on Haiku failure
   * When true, routing failures are logged but don't block workflow execution.
   * When false, routing failures may result in workflow errors.
   * @default true
   */
  fallbackToAgentDecision: boolean;
}

/**
 * Policy Engine enforcement mode
 * - 'LOG_ONLY': Log policy decisions without enforcement (safe for demos)
 * - 'ENFORCE': Enforce policy decisions (block unauthorized actions)
 */
export type PolicyMode = 'LOG_ONLY' | 'ENFORCE';

/**
 * Configuration for AgentCore Policy Engine integration
 * Controls Cedar policy enforcement for MCP Gateway tool invocations
 *
 * Note: policyEngineId and policyEngineArn are runtime values stored in
 * infrastructure.json, not in config.json. This follows the existing
 * pattern established for DynamoDB configuration.
 */
export interface PolicyConfig {
  /**
   * Policy Engine enforcement mode
   * - 'LOG_ONLY': Log policy decisions without enforcement (recommended for demos)
   * - 'ENFORCE': Enforce policy decisions and block unauthorized actions
   * @default "LOG_ONLY"
   */
  mode: PolicyMode;
}

/**
 * Cross-agent memory settings within memory configuration
 * Controls how agents share data within workflow sessions
 */
export interface CrossAgentMemoryConfig {
  /**
   * Enable cross-agent memory sharing
   * When enabled, agents can share fetched data via AgentCore Memory
   * @default true
   */
  enabled: boolean;

  /**
   * Memory retention period in days
   * After this period, stored memory items will expire
   * @default 7
   */
  expiryDays: number;
}

/**
 * Memory configuration for AgentCore Memory integration
 * Controls cross-agent memory sharing within workflow sessions
 *
 * Note: memoryId is a runtime value stored in infrastructure.json after
 * setup-memory.sh creates the memory resource, not in config.json.
 */
export interface MemoryConfig {
  /**
   * Cross-agent memory sharing settings
   * Controls whether agents share fetched data within a workflow session
   */
  crossAgent: CrossAgentMemoryConfig;
}

/**
 * Root configuration for an Agentify project
 * Stored in .agentify/config.json
 */
export interface AgentifyConfig {
  /**
   * Configuration schema version for forward compatibility
   * @example "1.0.0"
   */
  version: string;

  /**
   * Project metadata and business context
   */
  project: ProjectConfig;

  /**
   * Infrastructure settings (DynamoDB, Bedrock)
   */
  infrastructure: InfrastructureConfig;

  /**
   * Workflow definition and trigger configuration
   */
  workflow: WorkflowConfig;

  /**
   * AWS configuration for credential and profile management
   * Optional - when omitted, AWS SDK uses default credential resolution
   */
  aws?: AwsConfig;

  /**
   * Observability configuration (X-Ray, tracing)
   * Optional - when omitted, observability features are disabled
   */
  observability?: ObservabilityConfig;

  /**
   * Routing configuration for Haiku-based routing decisions
   * Optional - when omitted, Haiku routing is disabled (uses existing strategies)
   */
  routing?: RoutingConfig;

  /**
   * Policy configuration for AgentCore Policy Engine
   * Optional - when omitted, policy generation is skipped during Step 8
   * Note: policyEngineId and policyEngineArn are stored in infrastructure.json
   */
  policy?: PolicyConfig;

  /**
   * Memory configuration for AgentCore Memory integration
   * Optional - when omitted, cross-agent memory is disabled
   * Note: memoryId is stored in infrastructure.json after setup-memory.sh
   */
  memory?: MemoryConfig;
}

/**
 * Result of configuration validation
 */
export interface ConfigValidationResult {
  /**
   * Whether the configuration is valid
   */
  isValid: boolean;

  /**
   * Array of validation error messages (empty if valid)
   */
  errors: string[];
}

/**
 * Validates that a config object has all required fields
 *
 * Note: infrastructure.dynamodb is now OPTIONAL because new projects
 * don't have this until the user runs setup.sh, which creates
 * infrastructure.json with deployment outputs. The extension reads
 * from infrastructure.json first, falling back to config.json for
 * backward compatibility with existing projects.
 *
 * @param config The config object to validate
 * @returns Validation result with isValid flag and any errors
 */
export function validateConfigSchema(config: unknown): ConfigValidationResult {
  const errors: string[] = [];

  if (!config || typeof config !== 'object') {
    return { isValid: false, errors: ['Configuration must be an object'] };
  }

  const cfg = config as Record<string, unknown>;

  // Validate version
  if (typeof cfg.version !== 'string') {
    errors.push('Missing or invalid "version" field');
  }

  // Validate project
  if (!cfg.project || typeof cfg.project !== 'object') {
    errors.push('Missing or invalid "project" field');
  } else {
    const project = cfg.project as Record<string, unknown>;
    if (typeof project.name !== 'string') {
      errors.push('Missing or invalid "project.name" field');
    }
    if (typeof project.valueMap !== 'string') {
      errors.push('Missing or invalid "project.valueMap" field');
    }
    if (typeof project.industry !== 'string') {
      errors.push('Missing or invalid "project.industry" field');
    }
  }

  // Validate infrastructure
  if (!cfg.infrastructure || typeof cfg.infrastructure !== 'object') {
    errors.push('Missing or invalid "infrastructure" field');
  } else {
    const infra = cfg.infrastructure as Record<string, unknown>;

    // Validate infrastructure.dynamodb - NOW OPTIONAL
    // Only validate if present (for backward compatibility with existing projects)
    if (infra.dynamodb !== undefined) {
      if (typeof infra.dynamodb !== 'object' || infra.dynamodb === null) {
        errors.push('Invalid "infrastructure.dynamodb" field - must be an object when provided');
      } else {
        const dynamodb = infra.dynamodb as Record<string, unknown>;
        if (typeof dynamodb.tableName !== 'string') {
          errors.push('Missing or invalid "infrastructure.dynamodb.tableName" field');
        }
        if (typeof dynamodb.tableArn !== 'string') {
          errors.push('Missing or invalid "infrastructure.dynamodb.tableArn" field');
        }
        if (typeof dynamodb.region !== 'string') {
          errors.push('Missing or invalid "infrastructure.dynamodb.region" field');
        }
      }
    }
    // Note: If dynamodb is not present, that's OK - extension reads from infrastructure.json

    // Validate infrastructure.bedrock
    if (!infra.bedrock || typeof infra.bedrock !== 'object') {
      errors.push('Missing or invalid "infrastructure.bedrock" field');
    } else {
      const bedrock = infra.bedrock as Record<string, unknown>;
      if (typeof bedrock.modelId !== 'string') {
        errors.push('Missing or invalid "infrastructure.bedrock.modelId" field');
      } else if (bedrock.modelId.trim() === '') {
        errors.push('Invalid "infrastructure.bedrock.modelId" field - must be a non-empty string');
      }
      if (typeof bedrock.region !== 'string') {
        errors.push('Missing or invalid "infrastructure.bedrock.region" field');
      } else if (bedrock.region.trim() === '') {
        errors.push('Invalid "infrastructure.bedrock.region" field - must be a non-empty string');
      }
    }
  }

  // Validate workflow
  if (!cfg.workflow || typeof cfg.workflow !== 'object') {
    errors.push('Missing or invalid "workflow" field');
  } else {
    const workflow = cfg.workflow as Record<string, unknown>;

    // entryScript is optional (filled in after Kiro generates main.py)
    if (workflow.entryScript !== undefined && typeof workflow.entryScript !== 'string') {
      errors.push('Invalid "workflow.entryScript" - must be a string when provided');
    }

    // pythonPath is optional (defaults to "python3" if not specified)
    if (workflow.pythonPath !== undefined && typeof workflow.pythonPath !== 'string') {
      errors.push('Invalid "workflow.pythonPath" - must be a string when provided');
    }

    // orchestrationPattern is optional with default
    const validPatterns = ['graph', 'swarm', 'workflow'];
    if (workflow.orchestrationPattern !== undefined &&
        !validPatterns.includes(workflow.orchestrationPattern as string)) {
      errors.push('Invalid "workflow.orchestrationPattern" - must be "graph", "swarm", or "workflow"');
    }

    // agents and edges are optional arrays
    if (workflow.agents !== undefined && !Array.isArray(workflow.agents)) {
      errors.push('Invalid "workflow.agents" - must be an array when provided');
    }
    if (workflow.edges !== undefined && !Array.isArray(workflow.edges)) {
      errors.push('Invalid "workflow.edges" - must be an array when provided');
    }
  }

  // Validate optional aws section (backward compatible - section can be omitted)
  if (cfg.aws !== undefined) {
    if (typeof cfg.aws !== 'object' || cfg.aws === null) {
      errors.push('Invalid "aws" field - must be an object when provided');
    } else {
      const aws = cfg.aws as Record<string, unknown>;
      // Validate aws.profile when provided (optional field)
      if (aws.profile !== undefined) {
        if (typeof aws.profile !== 'string') {
          errors.push('Invalid "aws.profile" field - must be a string when provided');
        } else if (aws.profile.trim() === '') {
          errors.push('Invalid "aws.profile" field - must be a non-empty string when provided');
        }
      }
      // Validate aws.region when provided (optional field)
      if (aws.region !== undefined) {
        if (typeof aws.region !== 'string') {
          errors.push('Invalid "aws.region" field - must be a string when provided');
        } else if (aws.region.trim() === '') {
          errors.push('Invalid "aws.region" field - must be a non-empty string when provided');
        }
      }
    }
  }

  // Validate optional routing section
  if (cfg.routing !== undefined) {
    if (typeof cfg.routing !== 'object' || cfg.routing === null) {
      errors.push('Invalid "routing" field - must be an object when provided');
    } else {
      const routing = cfg.routing as Record<string, unknown>;

      // Validate routing.useHaikuRouter (boolean)
      if (routing.useHaikuRouter !== undefined && typeof routing.useHaikuRouter !== 'boolean') {
        errors.push('Invalid "routing.useHaikuRouter" field - must be a boolean when provided');
      }

      // Validate routing.routerModel (string)
      if (routing.routerModel !== undefined) {
        if (typeof routing.routerModel !== 'string') {
          errors.push('Invalid "routing.routerModel" field - must be a string when provided');
        } else if (routing.routerModel.trim() === '') {
          errors.push('Invalid "routing.routerModel" field - must be a non-empty string when provided');
        }
      }

      // Validate routing.fallbackToAgentDecision (boolean)
      if (routing.fallbackToAgentDecision !== undefined && typeof routing.fallbackToAgentDecision !== 'boolean') {
        errors.push('Invalid "routing.fallbackToAgentDecision" field - must be a boolean when provided');
      }
    }
  }

  // Validate optional policy section
  if (cfg.policy !== undefined) {
    if (typeof cfg.policy !== 'object' || cfg.policy === null) {
      errors.push('Invalid "policy" field - must be an object when provided');
    } else {
      const policy = cfg.policy as Record<string, unknown>;

      // Validate policy.mode (enum)
      const validModes = ['LOG_ONLY', 'ENFORCE'];
      if (policy.mode !== undefined) {
        if (typeof policy.mode !== 'string') {
          errors.push('Invalid "policy.mode" field - must be a string when provided');
        } else if (!validModes.includes(policy.mode)) {
          errors.push('Invalid "policy.mode" field - must be "LOG_ONLY" or "ENFORCE"');
        }
      }
    }
  }

  // Validate optional memory section
  if (cfg.memory !== undefined) {
    if (typeof cfg.memory !== 'object' || cfg.memory === null) {
      errors.push('Invalid "memory" field - must be an object when provided');
    } else {
      const memory = cfg.memory as Record<string, unknown>;

      // Validate memory.crossAgent (required when memory is present)
      if (memory.crossAgent === undefined) {
        errors.push('Missing "memory.crossAgent" field - required when memory is configured');
      } else if (typeof memory.crossAgent !== 'object' || memory.crossAgent === null) {
        errors.push('Invalid "memory.crossAgent" field - must be an object');
      } else {
        const crossAgent = memory.crossAgent as Record<string, unknown>;

        // Validate crossAgent.enabled (boolean)
        if (crossAgent.enabled !== undefined && typeof crossAgent.enabled !== 'boolean') {
          errors.push('Invalid "memory.crossAgent.enabled" field - must be a boolean when provided');
        }

        // Validate crossAgent.expiryDays (number)
        if (crossAgent.expiryDays !== undefined) {
          if (typeof crossAgent.expiryDays !== 'number') {
            errors.push('Invalid "memory.crossAgent.expiryDays" field - must be a number when provided');
          } else if (crossAgent.expiryDays < 1 || crossAgent.expiryDays > 365) {
            errors.push('Invalid "memory.crossAgent.expiryDays" field - must be between 1 and 365');
          }
        }
      }
    }
  }

  return {
    isValid: errors.length === 0,
    errors,
  };
}
